---
title: "Changelog"
description: "Product updates and announcements"
sidebarTitle: "Product updates"
---

<Update label="September 2025" description="v1.24">
  > **Expanded vLLM model catalog, faster launch times, and improved stability.**

  New pre-packaged vLLM models added (total of 10 now available):

  - Meta Llama-3.1 8B Instruct
  - Mistral Small-3.1 24B Instruct
  - Llama 3.3 70B Instruct
  - Mistral Small-24B Instruct
  - Qwen-2.5 VL 32B Instruct
  - GPT OSS 20B

  Improved launch speed for LLM models with local caching (70B models can take up to 45 minutes).

  Custom credit amounts now available for customers.

  New user profiling on first sign-up or login (optional).

  Stability improvements and bug fixes across workflows.
</Update>

<Update label="September 2025" description="v1.23">
  > **HTTPS support, new inference options, and smoother instance setup.** 

  HTTPS services are now available.

  vLLM inference servers added.

  Improved instance flow for smoother setup and management.

  More connectivity options introduced.
</Update>

<Update label="July 2025" description="v1.21">
  > **Instance controls, custom templates, and RTX 5090 support.**

  Stop and start your Compute instances.

  Custom templates now supported.

  Added RTX 5090 support.
</Update>